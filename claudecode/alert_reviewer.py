#!/usr/bin/env python3
"""
GitHub Code Scanning Alert Reviewer
Reviews existing open alerts and re-validates them to prevent inadvertent closure.
"""

import json
import os
import requests
import subprocess
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
from claudecode.logger import get_logger

logger = get_logger(__name__)


class AlertReviewer:
    """Reviews and re-validates existing GitHub Code Scanning alerts."""
    
    def __init__(self, github_token: str, repository: str):
        """Initialize alert reviewer.
        
        Args:
            github_token: GitHub token with security_events:read permission
            repository: Repository in format 'owner/repo'
        """
        self.github_token = github_token
        self.repository = repository
        self.headers = {
            'Authorization': f'Bearer {github_token}',
            'Accept': 'application/vnd.github+json',
            'X-GitHub-Api-Version': '2022-11-28'
        }
    
    def get_open_alerts(self) -> List[Dict[str, Any]]:
        """Retrieve all open Code Scanning alerts for the repository.
        
        Returns:
            List of open alert dictionaries
        """
        try:
            url = f"https://api.github.com/repos/{self.repository}/code-scanning/alerts"
            params = {
                'state': 'open',
                'per_page': 100  # GitHub's max per page
            }
            
            all_alerts = []
            page = 1
            
            while True:
                params['page'] = page
                response = requests.get(url, headers=self.headers, params=params)
                response.raise_for_status()
                
                alerts = response.json()
                if not alerts:
                    break
                
                all_alerts.extend(alerts)
                
                # Check if there are more pages
                if len(alerts) < 100:
                    break
                page += 1
            
            logger.info(f"Retrieved {len(all_alerts)} open Code Scanning alerts")
            return all_alerts
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Failed to retrieve Code Scanning alerts: {e}")
            return []
        except Exception as e:
            logger.error(f"Unexpected error retrieving alerts: {e}")
            return []
    
    def filter_claude_alerts(self, alerts: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Filter alerts to only include those from Claude Security Scanner.
        
        Args:
            alerts: List of all alerts
            
        Returns:
            List of Claude-generated alerts
        """
        claude_alerts = []
        
        for alert in alerts:
            tool = alert.get('tool', {})
            tool_name = tool.get('name', '').lower()
            
            # Check if this alert was generated by Claude Security Scanner
            if ('claude' in tool_name and 'security' in tool_name) or tool_name == 'claude security scanner':
                claude_alerts.append(alert)
        
        logger.info(f"Found {len(claude_alerts)} alerts from Claude Security Scanner")
        return claude_alerts
    
    def convert_alert_to_finding(self, alert: Dict[str, Any]) -> Dict[str, Any]:
        """Convert a GitHub Code Scanning alert to our finding format.
        
        Args:
            alert: GitHub Code Scanning alert
            
        Returns:
            Finding dictionary in our format
        """
        # Extract location information
        locations = alert.get('most_recent_instance', {}).get('location', {})
        file_path = locations.get('path', '')
        start_line = locations.get('start_line', 0)
        
        # Extract rule information  
        rule = alert.get('rule', {})
        rule_id = rule.get('id', 'unknown')
        rule_description = rule.get('description', '')
        
        # Map GitHub severity to our format
        severity_map = {
            'critical': 'CRITICAL',
            'high': 'HIGH', 
            'medium': 'MEDIUM',
            'low': 'LOW',
            'warning': 'MEDIUM',
            'note': 'LOW',
            'error': 'HIGH'
        }
        
        github_severity = alert.get('rule', {}).get('severity', 'medium').lower()
        our_severity = severity_map.get(github_severity, 'MEDIUM')
        
        # Create finding
        finding = {
            'file': file_path,
            'line': start_line,
            'severity': our_severity,
            'category': rule_id,
            'description': rule_description,
            'confidence': 1.0,  # High confidence for existing alerts
            'exploit_scenario': f'This is an existing Code Scanning alert (#{alert.get("number", "unknown")}) that remains unresolved.',
            'recommendation': f'Address this previously identified security issue. Alert URL: {alert.get("html_url", "")}',
            '_alert_metadata': {
                'alert_number': alert.get('number'),
                'alert_url': alert.get('html_url'),
                'created_at': alert.get('created_at'),
                'state': alert.get('state'),
                'from_existing_alert': True
            }
        }
        
        return finding
    
    def validate_alert_still_exists(self, alert: Dict[str, Any], repo_path: Path) -> bool:
        """Validate that the code issue for an alert still exists in the current codebase.
        
        Args:
            alert: GitHub Code Scanning alert
            repo_path: Path to the repository
            
        Returns:
            True if the issue likely still exists
        """
        try:
            # Extract file and line information
            locations = alert.get('most_recent_instance', {}).get('location', {})
            file_path = locations.get('path', '')
            start_line = locations.get('start_line', 0)
            end_line = locations.get('end_line', start_line)
            
            if not file_path:
                return False
            
            # Check if file still exists
            full_file_path = repo_path / file_path
            if not full_file_path.exists():
                logger.info(f"Alert file no longer exists: {file_path}")
                return False
            
            # Read the file and check if the line range still exists
            try:
                with open(full_file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    file_lines = f.readlines()
                
                # Check if line numbers are still valid
                if start_line > len(file_lines):
                    logger.info(f"Alert line {start_line} beyond file length {len(file_lines)} in {file_path}")
                    return False
                
                # For authentication/authorization issues, check if suspicious patterns still exist
                rule = alert.get('rule', {})
                rule_id = rule.get('id', '').lower()
                
                if any(keyword in rule_id for keyword in ['auth', 'authorization', 'bypass', 'idor']):
                    # Look for patterns that might indicate the issue is resolved
                    relevant_lines = file_lines[max(0, start_line-5):min(len(file_lines), end_line+5)]
                    content = ''.join(relevant_lines).lower()
                    
                    # Check for signs the issue might be fixed
                    fixed_patterns = [
                        'before_action',
                        'authorize!',
                        'current_user',
                        'can?',
                        'policy',
                        'authenticate',
                        'require_user'
                    ]
                    
                    if any(pattern in content for pattern in fixed_patterns):
                        logger.debug(f"Alert may be fixed: found auth patterns near line {start_line} in {file_path}")
                        # Don't automatically exclude - let the new scan determine if it's really fixed
                        return True  # Still conservative
                
                logger.debug(f"Alert validation: file {file_path} line {start_line} still exists")
                return True
                
            except Exception as e:
                logger.warning(f"Could not read file {file_path}: {e}")
                return True  # Conservative: assume it exists if we can't read
            
        except Exception as e:
            logger.warning(f"Failed to validate alert: {e}")
            return True  # Conservative: assume it still exists if we can't validate
    
    def review_and_persist_alerts(self, repo_path: Path) -> List[Dict[str, Any]]:
        """Review open alerts and return findings for those that should persist.
        
        Args:
            repo_path: Path to the repository
            
        Returns:
            List of findings to persist in SARIF
        """
        logger.info("Starting review of existing Code Scanning alerts")
        
        # Get all open alerts
        open_alerts = self.get_open_alerts()
        if not open_alerts:
            logger.info("No open Code Scanning alerts found")
            return []
        
        # Filter to Claude-generated alerts
        claude_alerts = self.filter_claude_alerts(open_alerts)
        if not claude_alerts:
            logger.info("No open alerts from Claude Security Scanner found")
            return []
        
        # Validate and convert alerts to findings
        persistent_findings = []
        
        for alert in claude_alerts:
            alert_number = alert.get('number', 'unknown')
            
            # Validate the alert still represents a real issue
            if self.validate_alert_still_exists(alert, repo_path):
                finding = self.convert_alert_to_finding(alert)
                persistent_findings.append(finding)
                logger.info(f"Persisting alert #{alert_number}: {finding['category']} in {finding['file']}")
            else:
                logger.info(f"Alert #{alert_number} appears to be resolved, not persisting")
        
        logger.info(f"Persisting {len(persistent_findings)} existing alerts")
        return persistent_findings


def integrate_alert_review(github_token: str, repository: str, repo_path: Path, 
                          current_findings: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Integrate alert review into the security scanning process.
    
    Args:
        github_token: GitHub token
        repository: Repository name
        repo_path: Path to repository
        current_findings: Findings from current scan
        
    Returns:
        Combined findings including persistent alerts
    """
    try:
        # Initialize alert reviewer
        reviewer = AlertReviewer(github_token, repository)
        
        # Get findings from existing alerts
        persistent_findings = reviewer.review_and_persist_alerts(repo_path)
        
        if not persistent_findings:
            logger.info("No existing alerts to persist")
            return current_findings
        
        # Combine with current findings, avoiding duplicates
        combined_findings = list(current_findings)
        
        # Simple deduplication based on file, line, and category
        existing_signatures = set()
        for finding in current_findings:
            signature = f"{finding.get('file', '')}:{finding.get('line', 0)}:{finding.get('category', '')}"
            existing_signatures.add(signature)
        
        # Add persistent findings that don't duplicate current ones
        added_count = 0
        for persistent_finding in persistent_findings:
            signature = f"{persistent_finding.get('file', '')}:{persistent_finding.get('line', 0)}:{persistent_finding.get('category', '')}"
            
            if signature not in existing_signatures:
                # Mark as persistent alert with special metadata
                persistent_finding['_filter_metadata'] = {
                    'confidence_score': 10.0,
                    'justification': 'Persistent alert from previous Code Scanning results'
                }
                combined_findings.append(persistent_finding)
                added_count += 1
                existing_signatures.add(signature)
        
        logger.info(f"Added {added_count} persistent alerts to findings (avoided {len(persistent_findings) - added_count} duplicates)")
        return combined_findings
        
    except Exception as e:
        logger.error(f"Alert review integration failed: {e}")
        # Return original findings if alert review fails
        return current_findings